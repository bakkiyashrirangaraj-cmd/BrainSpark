# BrainSpark - Database Migration Cloud Build
# File: cloudbuild-migrate.yaml
#
# Runs database migrations against Cloud SQL
#
# Usage:
#   gcloud builds submit --config=cloudbuild-migrate.yaml

steps:
  # Step 1: Build migration container
  - name: 'gcr.io/cloud-builders/docker'
    id: 'build-migration'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        cat > /workspace/Dockerfile.migrate << 'EOF'
        FROM python:3.11-slim
        RUN apt-get update && apt-get install -y postgresql-client && rm -rf /var/lib/apt/lists/*
        RUN pip install psycopg2-binary sqlalchemy alembic
        WORKDIR /app
        COPY database/schema.sql /app/
        COPY backend/alembic* /app/ 2>/dev/null || true
        EOF
        docker build -t migration-runner -f /workspace/Dockerfile.migrate .

  # Step 2: Run schema initialization
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'init-schema'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Running database schema initialization..."

        # Get database password from Secret Manager
        DB_PASSWORD=$(gcloud secrets versions access latest --secret=db-password)

        # Get Cloud SQL instance IP (assumes private IP)
        # For Cloud SQL proxy, use different approach

        echo "Schema initialization would run here"
        echo "In production, use Cloud SQL Auth Proxy or private IP"

        # Example with Cloud SQL Proxy:
        # cloud_sql_proxy -instances=${PROJECT_ID}:${_REGION}:brainspark-db=tcp:5432 &
        # sleep 5
        # PGPASSWORD=$DB_PASSWORD psql -h 127.0.0.1 -U brainspark -d brainspark -f /workspace/database/schema.sql
    waitFor: ['build-migration']

  # Step 3: Verify database
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    id: 'verify-db'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Database migration complete"
        echo ""
        echo "To manually run migrations:"
        echo "1. Connect to Cloud SQL using Auth Proxy"
        echo "2. Run: psql -f database/schema.sql"
    waitFor: ['init-schema']

# Substitution variables
substitutions:
  _REGION: 'asia-south1'
  _DB_INSTANCE: 'brainspark-db'

# Build options
options:
  logging: CLOUD_LOGGING_ONLY

# Timeout
timeout: '300s'

# Tags
tags:
  - 'brainspark'
  - 'database'
  - 'migration'
